一、准备虚拟机，所用版本VMware-workstation-full-10.0.3-1895310
二、安装CentOS，所用版本CentOS-6.5-i386-bin-DVD1
	网络适配器：桥接模式
	关selinux 和 iptables
	[root@base ~]# vi /etc/selinux/config
	[root@base ~]# chkconfig iptables off
三、安装JDK(jdk-6u45-linux-i586.bin)配置环境/etc/profile
 1、干掉系统自带openjdk：
	rpm -qa | grep java
	改root用户
	rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.i686
	java -version
	rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.i686
	vi /etc/profile
	source /etc/profile

 2、安装：
	cd /home/hadoop
	./jdk-6u45-linux-i586.bin
 3、配环境:
	vi /etc/profile
	
	export JAVA_HOME=/usr/java/jdk1.6.0_45
	export JRE_HOME=$JAVA_HOME/jre
	export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
	export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
	
	.bash_logout 配置用户登录出去执行什么
	.bash_profile 配置用户特殊的profile
	.bashrc 配置bash专用的(bash是一种shell linux 可以有很多种shell 比如C shell 就是C语言风格的shell 如果用C shell 这个文件就没用了)
 4、配置/etc/sysconfig/network-scripts/ifcfg-eth0
	DEVICE=eth0
	#复制的虚拟机需要改这个硬件地址(也叫网卡的MAC地址)
	HWADDR=00:0C:29:01:FF:78
	TYPE=Ethernet
	UUID=0ca7c5f6-daff-4f43-ae2b-d4155e687d60
	#开机启动网卡
	ONBOOT=yes
	NM_CONTROLLED=yes
	#使用静态IP配置
	BOOTPROTO=static
	#对应的子网广播地址
	BROADCAST=192.168.36.255
	#网卡对应的网段地址
	NETWORK=192.168.36.0
	#设置网卡获得的IP地址
	IPADDR=192.168.36.129
	#网卡对应的网络掩码
	NETMASK=255.255.255.0
	#设置Linux的网关(由虚拟机网络配置决定)
	GATEWAY=192.168.36.2
	#设置Linux的DNS(由虚拟机网络配置决定通常网关也是内网DNS，转发DNS请求)
	DNS1=192.168.36.2
	有外网测试安装setuptool
	yum -y install setuptool
	没有外网 ifconfig 看有否有 eth0 并且eth0 有IP 能ping通其他的虚拟机
 5、修改/etc/hosts
	192.168.36.130 master
	192.168.36.131 slave1
	192.168.36.132 slave2
	192.168.36.133 slave3
 6、修改 /etc/security/limits.conf 最后加 配置最大线程和文件打开数
	* - nproc 65535
	* - nofile 65535

 7、确保创建了 hadoop 这个用户 实现无密码验证登录
	su - hadoop
	mkdir ~/.ssh
	cd ~/.ssh
	ssh-keygen -t rsa -P ''
	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

	chmod 600 authorized_keys
	root 用户编辑 /etc/ssh/sshd_config
	vi /etc/ssh/sshd_config
	去掉 26行 左右 以下配置的注释
	HostKey /etc/ssh/ssh_host_rsa_key

	去掉 47 48 49 行的注释 (对应下面这三行)
	RSAAuthentication yes
	PubkeyAuthentication yes
	AuthorizedKeysFile      .ssh/authorized_keys

 8、配置.ssh权限防止没权限读取ssh的秘钥
	***一定要使用hadoop用户执行不能root代劳***
	chown -R hadoop:hadoop /home/hadoop
	chmod 700 /home/hadoop
	chmod 700 /home/hadoop/.ssh
	chmod 644 /home/hadoop/.ssh/authorized_keys
	chmod 600 /home/hadoop/.ssh/id_rsa
四、安装hadoop
 1、将hadoop 1.0.4 传到 虚拟机 放到 /home/hadoop 目录下
	解压：
	tar -vxzf hadoop-1.0.4.tar.gz
	修改解压后的目录名
	mv hadoop-1.0.4 hadoop
	创建文件夹：
	mkdir ~/hadoop/data
	mkdir ~/hadoop/tmp
	chmod 755 ~/hadoop/data
	chmod 755 ~/hadoop/tmp

 2、配置hadoop用户目录下的 ~/.bash_profile
	将以下内容编辑到文本末尾：
	export HADOOP_HOME=/home/hadoop/hadoop
	export PATH=$PATH:$HADOOP_HOME/bin
 3、统一修改hadoop用户conf目录(~/hadoop/conf)下的各种配置文件
	修改配置文件hadoop-env.sh
	搜索到JAVA_HOME所在行，然后将默认的“#”去掉，也就是打开注释，然后如下配置：
	export JAVA_HOME=/usr/java/jdk1.6.0_45

 4、修改配置文件 core-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>
		  <name>fs.default.name</name>
		  <value>hdfs://master:9000</value>
	 </property>
	</configuration>

 5、修改配置文件 hdfs-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>  
	  <name>dfs.replication</name>
	  <value>3</value>
	 </property>            
	 <property>  
	   <name>dfs.name.dir</name>  
	   <value>/home/hadoop/hadoop/namenode/</value>  
	  </property> 
	  <property>  
	   <name>dfs.data.dir</name>  
	   <value>/home/hadoop/hadoop/data/</value>  
	  </property>               
	  <property>  
		<name>hadoop.tmp.dir</name>  
		<value>/home/hadoop/hadoop/tmp/</value>  
	  </property>
	  <property>
	   <name>dfs.permissions</name>
	   <value>false</value>
	  </property>
	</configuration>

 6、修改配置文件 mapred-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>  
	   <name>mapred.job.tracker</name>  
	   <value>master:9001</value>  
	 </property>
	 <property>  
	   <name>mapred.tasktracker.map.tasks.maximum</name>  
	   <value>2</value>  
	 </property>                  
	 <property>  
		<name>mapred.tasktracker.reduce.tasks.maximum</name>  
		<value>2</value>  
	 </property>  
	</configuration>

 7、修改配置文件 masters
	配置如下：
	master

 8、修改配置文件 slaves
	配置如下：
	slave1
	slave2
	slave3
 9、复制4份虚拟机 并配置静态IP
	vm_master 192.168.24.130
	vm_slave1 192.168.24.131
	vm_slave2 192.168.24.132
	vm_slave3 192.168.24.133
	############################################################################
	hadoop namenode -format
	启动hadoop：
	start-all.sh
 10、启动后使用jps命令查看：
	NN上：
	jps
	namenode 1002
	secondarynamenode 1011
	jobtracker 1012
	DN上：
	jps
	datanode 2
	tasktracker 10
	然后通过http://master:50070和http://master:50030查看监控界面。
 11、如果有异常，查看日志
	hadoop logs中
	查看日志：
		hadoop-hadoop-namenode-master.log
	删除所有日志：
	rm -rf hadoop-hadoop-*

	hadoop namenode -format
	start-all.sh   stop-all.sh
	start-hbase.sh stop-hbase.sh

	退出安全模式：
	hadoop dfsadmin -safemode leave
五、配置hbase：
 1、解压：
	tar hbase-0.94.6.tar.gz
	修改文件夹名字为hbase
	********
 2、配置环境变量：
	切换到root
	vi /etc/profile
	打开vi编辑器，添加以下内容到末尾
	export HBASE_HOME=/home/hadoop/hbase
	export PATH=$PATH:$HBASE_HOME/bin
	
 3、修改hbase配置文件
	退回hadoop用户：
	cd ~/hbase/conf
	vi hbase-env.sh
	打开vi编辑器，解封修改JAVA_HOME添加以下内容：
	export JAVA_HOME=/home/hadoop/jdk1.6.0_45
	export HBASE_CLASSPATH=/home/hadoop/hbase/conf
	export HBASE_MANAGES_ZK=true
	
 4、修改hbase-site.sh
	打开vi编辑器，配置如下：
	<configuration>
		//配置主机地址
		<property>
			<name>hbase.master</name>
			<value>master:60000</value>
		</property>
		//配置时间差
		<property>
			<name>hbase.master.maxclockskew</name>
			<value>180000</value>
		</property>
		//数据存在HDFS上
		<property>
			<name>hbase.rootdir</name>
			<value>hdfs://master:9000/hbase</value>
		</property>
		<property>
			<name>hbase.cluster.distributed</name>
			<value>true</value>
		</property>
		//配置从节点
		<property>
			<name>hbase.zookeeper.quorum</name>
			<value>slave1,slave2,slave3</value>
		</property>
		<property>
			<name>hbase.zookeeper.property,datadir</name>
			<value>/home/${user.name}/tmp/zookeeper</value>
		</property>
	</configuratuon> 
 5、通过vi工具修改配置文件reginservers
	vi reginservers
	配置如下：
	slave1
	slave2 
	slave3
	
	用scp命令将hbase文件夹拷贝给其他机器
	eg：scp -r /home/hadoop/hbase  hadoop@192.168.24.132:/home/hadoop
	
 6、启动hbase集群，进入监控页面查看
	首先，必须保证hadoop是启动状态的
	启动hbase：
	start-hbase.sh
	启动后使用jps命令查看
	查看从机上jps状态
 7、通过http://master:60010查看监控界面
	关闭hbase：
	stop-hbase.sh
	关闭hadoop:
	stop-all.sh
	
	hadoop dfsadmin -safemode leave
六、配置zookeeper
 1、切到hadoop用户，解压缩zookeeper-3.4.5.tar.gz
	tar -zxvf zookeeper-3.4.5.tar.gz
	改名字：
	mv zookeeper-3.4.5 zookeeper
 2、配置zookeeper环境变量，切到root用户
	vi /etc/profile
	打开vi编辑器，在文本末尾添加以下内容：
	export ZOOKEEPER_HOME=/home/hadoop/zookeeper
	export PATH =$PATH:$ZOOKEEPER_HOME/bin
 3、准备两个文件夹data和log来存放zookeeper的数据和日志
	mkdir /home/hadoop/zookeeper/data
	chmod 755 /home/hadoop/zookeeper/data
	mkdir /home/hadoop/zookeeper/log
	chmod 755 /home/hadoop/zookeeper/log
 4、data目录下面新建myid文件，myid是文件内容分别为：1，zookeeper02为2，...
	在/home/hadoop/zookeeper/conf目录下面复制zoo_sample.cfg文件为zoo.cfg
	cp zoo_sample.cfg zoo.cfg
 5、通过vi工具修改配置文件zoo.cfg 按如下配置
	vi zoo.cfg
	dataDir=/home/hadoop/zookeeper/data
	dataLogDir=/home/hadoop/zookeeper/log
	server.1=slave1:2888:3888
	server.2=slave2:2888:3888
	server.3=slave3:2888:3888
	
 6、一个个的启动每个zookeeper节点：
	zkServer.sh start
	所有节点都启动后使用命令查看状态：
	zkServer.sh status
	其中只有一个leader 其他的都是flower即为成功。
	
	
	
www.jdon.com


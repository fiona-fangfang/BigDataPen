----------------------------------------------------------------------------------------------------
						1.网络和JDK的配置
说明：这次配置是使用的Linux CentOS 64位系统进行配置的 辅助软件为 SSH
由于在安装Linux的时候 使用的是NAT网络连接 所以在启动虚拟机和Linux之后 打开虚拟机左面的编辑，点开菜单
下方的虚拟网络编辑器这时候会看到有3个选项 我们是NAT连接 所以只看最后一个的VMnet8, 点击 发现下面的
子网IP 是192.168.xxx.xxx 请将这个子网IP 进行一次记录 在VMnet信息中 可以看到NAT设置 点击会出现网关
会出现网关IP 也将网关IP进行记录  这时候会注意到 子网IP的第三段和网管的第三段是一致的。这样 在Terminal
中输入 ifconfig  就会显示出你现在自动分配的IP 使用SSH 和这个IP 将WINDOWS 和Linux 进行连接 
------使用root------并且将jdk-6u45-linux-x64-rpm.bin 放到目录下
chmod 777 jdk-6u45-linux-x64-rpm.bin 修改文件属性
 ./jdk-6u45-linux-x64-rpm.bin  将文件进行安装 
安装结束后 使用 rm -rf *.rpm 把所有安装残余文件删除
vi /etc/profile 进行jdk环境变量的配置

JAVA_HOME=/usr/java/jdk1.6.0_45
JRE_HOME=$JAVA_HOME/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH
然后使用 source /etc/profile 进行对环境变量的更新 
使用java -version 进行检查 
如果出现的是
		java version "1.7.0_45"
		OpenJDK Runtime Environment (rhel-2.4.3.3.el6-x86_64 u45-b15)
		OpenJDK 64-Bit Server VM (build 24.45-b08, mixed mode)
那么就需要进行手动删除
rpm -e --nodeps java-1.7.0-openjdk-*
rpm -e --nodeps java-1.6.0-openjdk-*
这里注意 如果提示1.7的版本 那么需要从1.7 到1。6版本进行2次删除
 source /etc/profile  重新 java -version 
 结果就会变成了 
		java version "1.6.0_45"
		Java(TM) SE Runtime Environment (build 1.6.0_45-b06)
		Java HotSpot(TM) 64-Bit Server VM (build 20.45-b01, mixed mode)
环境变量配置OVER！！！
vi /etc/sysconfig/network-scripts/ifcfg-eth0  进入网络配置进行修改
BOOTPROTO=dhcp  修改为   BOOTPROTO=static
在文件后端 添加2行
IPADDR=192.168.112.140
GATEWAY=192.168.112.2
注意 这里的 112 是我在之前查看的子网IP 每个人的机器不一样 修改掉就好
后面的GATEWAY 是网关IP 请将自己的机器的网关IP地址不做任何修改 复制进来
service network restart 
然后再使用ifconfig 进行查看 会看到你的IP 已经改变到了 192.168.112.140
注意： 这个时候你的SSH 应该会提示断开连接 因为IP已经改变 将SSH中的IP改回来就好了
现在 需要想清楚 自己的主 从 各叫什么名字 以及占用什么IP 
比如 
192.168.112.140 master
192.168.112.141 slave1
192.168.112.142 slave2 
vi /etc/hosts  将上面的东西编辑 写进文件当中
vi /etc/sysconfig/network  将文件中的  HOSTNAME=XXXX 修改成 master ---主的名称
----------------------------------------------------------------------------------------------------
****************************************************************************************************
----------------------------------------------------------------------------------------------------
					我是华丽的分割线
----------------------------------------------------------------------------------------------------
****************************************************************************************************
----------------------------------------------------------------------------------------------------
					2 Hadoop的安装和配置阶段
在安装之前做好准备工作 
 adduser hadoop  创建一个名字叫做hadoop的用户  回车
 passwd hadoop   为这个用户创建密码为 hadoop 
 下面会显示这样 只要再输入一次hadoop   这样我们的hadoop 用户就创建好了
---Changing password for user hadoop.
New password: 
BAD PASSWORD: it is based on a dictionary word
BAD PASSWORD: is too simple
Retype new password: 
passwd: all authentication tokens updated successfully.
**************su hadoop  ***********************@@@@@@@@@这里使用hadoop 用户了 不再是root用户了 注意 注意 
将hadoop-1.0.4.tar.gz 复制到hadoop用户目录下
tar -vxzf hadoop-1.0.4.tar.gz 进行解压缩
mv hadoop-1.0.4 /home/hadoop/hadoop 将这个解压缩后的文件夹移动并且改名 
*************切换到root 用户 *************
vi /etc/profile 进行环境变量编辑
export HADOOP_HOME=/home/hadoop/hadoop
export PATH=$PATH:$HADOOP_HOME/bin 
添加到文件结尾 保存退出
再次切换回来到hadoop 用户下
**************************************************************
cd /home/hadoop/hadoop/conf  对hadoop的配置文件进行修改
**************************************************************
1 hadoop-env.sh
vi hadoop-env.sh  打开这个文件
export JAVA_HOME=/usr/java/jdk1.6.0_45 写入文件最下面 保存 退出
2 core-site.xml
vi core-site.xml  打开这个文件
<property>
      <name>fs.default.name</name>
      <value>hdfs://master:9000</value>
 </property> 写入到 configuration 中 保存退出
3 hdfs-site.xml 
vi hdfs-site.xml 打开
<property>  
  <name>dfs.replication</name>
  <value>3</value>
 </property>            
 <property>  
   <name>dfs.name.dir</name>  
   <value>/home/hadoop/hadoop/namenode/</value>  
  </property> 
  <property>  
   <name>dfs.data.dir</name>  
   <value>/home/hadoop/hadoop/data/</value>  
  </property>               
  <property>  
    <name>hadoop.tmp.dir</name>  
    <value>/home/hadoop/hadoop/tmp/</value>  
  </property>
  <property>
   <name>dfs.permissions</name>
   <value>false</value>
  </property> 
4 mapred-site.xml
vi mapred-site.xml 
 <property>  
   <name>mapred.job.tracker</name>  
   <value>master:9001</value>  
 </property>
 <property>  
   <name>mapred.tasktracker.map.tasks.maximum</name>  
   <value>2</value>  
 </property>                  
 <property>  
    <name>mapred.tasktracker.reduce.tasks.maximum</name>  
    <value>2</value>  
 </property>  
5 masters
修改masters 文件  将 localhost 修改为master
6 修改slaves 文件 将localhost 修改为 slave1 slave2  这里有几个从 写几个从 注意和之前的名字保持一致就好
还有就是注意 一行写一个
7 mkdir ~/hadoop/data/
mkdir ~/hadoop/tmp/
chmod 755 ~/hadoop/data/
chmod 755 ~/hadoop/tmp/
创建2个文件夹  并且赋予权限
这时候hadoop的最基本配置已经完成 
----------------------------------------------------------------------------------------------------
****************************************************************************************************
----------------------------------------------------------------------------------------------------
					华丽的分割线
----------------------------------------------------------------------------------------------------
****************************************************************************************************
----------------------------------------------------------------------------------------------------
					3 Hbase 的安装和配置
首先 使用hadoop 用户将hbase 复制进linux
tar -vxzf hbase-0.94.6.tar.gz  进行解压缩 
使用root 用户 环境变量进行修改
export HBASE_HOME=/home/hadoop/hbase
export PATH=$PATH:$HBASE_HOME/bin

----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
